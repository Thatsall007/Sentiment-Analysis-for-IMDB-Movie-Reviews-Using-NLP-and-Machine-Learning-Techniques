{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis is a common NLP task that Data Scientists need to perform. This is a straightforward guide to creating a barebones movie review classifier in Python. Future parts of this series will focus on improving the classifier.\n",
        "\n",
        "Data Overview For this analysis we’ll be using a dataset of 50,000 movie reviews taken from IMDb.\n",
        "\n",
        "The data is split evenly with 25k reviews intended for training and 25k for testing your classifier. Moreover, each set has 12.5k positive and 12.5k negative reviews.\n",
        "\n",
        "IMDb lets users rate movies on a scale from 1 to 10. To label these reviews the curator of the data labeled anything with ≤ 4 stars as negative and anything with ≥ 7 stars as positive. Reviews with 5 or 6 stars were left out.\n"
      ],
      "metadata": {
        "id": "csnoikMF4TtO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kzk9Wake4Kz1"
      },
      "outputs": [],
      "source": [
        "reviews_train = []\n",
        "for line in open('/content/full_train.txt', 'r', encoding=\"utf8\"):\n",
        "    reviews_train.append(line.strip())\n",
        "\n",
        "reviews_test = []\n",
        "for line in open('/content/full_test.txt', 'r', encoding=\"utf8\"):\n",
        "    reviews_test.append(line.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The raw text is pretty messy for these reviews so before we can do any analytics we need to clean things up. Here’s one example:\n",
        "\n",
        "\"This isn't the comedic Robin Williams, nor is it the quirky/insane Robin Williams of recent thriller fame. This is a hybrid of the classic drama without over-dramatization, mixed with Robin's new love of the thriller. But this isn't a thriller, per se. This is more a mystery/suspense vehicle through which Williams attempts to locate a sick boy and his keeper.\n",
        "\n",
        "Also starring Sandra Oh and Rory Culkin, this Suspense Drama plays pretty much like a news report, until William's character gets close to achieving his goal.\n",
        "\n",
        "I must say that I was highly entertained, though this movie fails to teach, guide, inspect, or amuse. It felt more like I was watching a guy (Williams), as he was actually performing the actions, from a third person perspective. In other words, it felt real, and I was able to subscribe to the premise of the story.\n",
        "\n",
        "All in all, it's worth a watch, though it's definitely not Friday/Saturday night fare.\n",
        "\n",
        "It rates a 7.7/10 from...\n",
        "\n"
      ],
      "metadata": {
        "id": "5boHaJpQ5IsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
        "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "\n",
        "def preprocess_reviews(reviews):\n",
        "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
        "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
        "\n",
        "    return reviews\n",
        "\n",
        "reviews_train_clean = preprocess_reviews(reviews_train)\n",
        "reviews_test_clean = preprocess_reviews(reviews_test)"
      ],
      "metadata": {
        "id": "p-hD_gkW5CSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And this is what the same review looks like now:\n",
        "\n",
        "\"this isnt the comedic robin williams nor is it the quirky insane robin williams of recent thriller fame this is a hybrid of the classic drama without over dramatization mixed with robins new love of the thriller but this isnt a thriller per se this is more a mystery suspense vehicle through which williams attempts to locate a sick boy and his keeper also starring sandra oh and rory culkin this suspense drama plays pretty much like a news report until williams character gets close to achieving his goal i must say that i was highly entertained though this movie fails to teach guide inspect or amuse it felt more like i was watching a guy williams as he was actually performing the actions from a third person perspective in other words it felt real and i was able to subscribe to the premise of the story all in all its worth a watch though its definitely not friday saturday night fare it rates a from the fiend\"\n",
        "\n",
        "Note: There are a lot of different and more sophisticated ways to clean text data that would likely produce better results than what I’ve done here. I wanted part 1 of this tutorial to be as simple as possible. Also, I generally think it’s best to get baseline predictions with the simplest possible solution before spending time doing potentially unnecessary transformations.\n",
        "\n",
        "Vectorization In order for this data to make sense to our machine learning algorithm we’ll need to convert each review to a numeric representation, which we call vectorization.\n",
        "\n",
        "The simplest form of this is to create one very large matrix with one column for every unique word in your corpus (where the corpus is all 50k reviews in our case). Then we transform each review into one row containing 0s and 1s, where 1 means that the word in the corpus corresponding to that column appears in that review. That being said, each row of the matrix will be very sparse (mostly zeros). This process is also known as one hot encoding."
      ],
      "metadata": {
        "id": "0bntXMKA5R1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(reviews_train_clean)\n",
        "X = cv.transform(reviews_train_clean)\n",
        "X_test = cv.transform(reviews_test_clean)"
      ],
      "metadata": {
        "id": "KMqUmnL05CPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "\n",
        "    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=1000)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\"\n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "\n",
        "#     Accuracy for C=0.01: 0.87472\n",
        "#     Accuracy for C=0.05: 0.88368\n",
        "#     Accuracy for C=0.25: 0.88016\n",
        "#     Accuracy for C=0.5: 0.87808\n",
        "#     Accuracy for C=1: 0.87648"
      ],
      "metadata": {
        "id": "Z2J2EF_p5CNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = LogisticRegression(C=0.05, solver='lbfgs', max_iter=1000)\n",
        "final_model.fit(X, target)\n",
        "print (\"Final Accuracy: %s\"\n",
        "       % accuracy_score(target, final_model.predict(X_test)))\n",
        "# Final Accuracy: 0.88128"
      ],
      "metadata": {
        "id": "JCo71F6j5CA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_to_coef = {\n",
        "    word: coef for word, coef in zip(\n",
        "        cv.get_feature_names_out(), final_model.coef_[0]\n",
        "    )\n",
        "}\n",
        "for best_positive in sorted(\n",
        "    feature_to_coef.items(),\n",
        "    key=lambda x: x[1],\n",
        "    reverse=True)[:5]:\n",
        "    print (best_positive)\n",
        "\n",
        "#     ('excellent', 0.9288812418118644)\n",
        "#     ('perfect', 0.7934641227980576)\n",
        "#     ('great', 0.675040909917553)\n",
        "#     ('amazing', 0.6160398142631545)\n",
        "#     ('superb', 0.6063967799425831)\n",
        "\n",
        "for best_negative in sorted(\n",
        "    feature_to_coef.items(),\n",
        "    key=lambda x: x[1])[:5]:\n",
        "    print (best_negative)\n",
        "\n",
        "#     ('worst', -1.367978497228895)\n",
        "#     ('waste', -1.1684451288279047)\n",
        "#     ('awful', -1.0277001734353677)\n",
        "#     ('poorly', -0.8748317895742782)\n",
        "#     ('boring', -0.8587249740682945)"
      ],
      "metadata": {
        "id": "1sKdY2R05ZYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "english_stop_words = stopwords.words('english')\n",
        "def remove_stop_words(corpus):\n",
        "    removed_stop_words = []\n",
        "    for review in corpus:\n",
        "        removed_stop_words.append(\n",
        "            ' '.join([word for word in review.split()\n",
        "                      if word not in english_stop_words])\n",
        "        )\n",
        "    return removed_stop_words\n",
        "\n",
        "no_stop_words = remove_stop_words(reviews_train_clean)"
      ],
      "metadata": {
        "id": "j078NxTl5ZV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stemmed_text(corpus):\n",
        "    from nltk.stem.porter import PorterStemmer\n",
        "    stemmer = PorterStemmer()\n",
        "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
        "\n",
        "stemmed_reviews = get_stemmed_text(reviews_train_clean)"
      ],
      "metadata": {
        "id": "fzg3TGp95ZSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lemmatized_text(corpus):\n",
        "    from nltk.stem import WordNetLemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
        "\n",
        "lemmatized_reviews = get_lemmatized_text(reviews_train_clean)\n"
      ],
      "metadata": {
        "id": "CoQooEXR5ZPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
        "ngram_vectorizer.fit(reviews_train_clean)\n",
        "X = ngram_vectorizer.transform(reviews_train_clean)\n",
        "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "\n",
        "    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=1000)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\"\n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "\n",
        "# Accuracy for C=0.01: 0.88416\n",
        "# Accuracy for C=0.05: 0.892\n",
        "# Accuracy for C=0.25: 0.89424\n",
        "# Accuracy for C=0.5: 0.89456\n",
        "# Accuracy for C=1: 0.8944\n",
        "\n",
        "final_ngram = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000)\n",
        "final_ngram.fit(X, target)\n",
        "print (\"Final Accuracy: %s\"\n",
        "       % accuracy_score(target, final_ngram.predict(X_test)))\n",
        "\n",
        "# Final Accuracy: 0.898"
      ],
      "metadata": {
        "id": "OHrGqxJ15ZNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wc_vectorizer = CountVectorizer(binary=False)\n",
        "wc_vectorizer.fit(reviews_train_clean)\n",
        "X = wc_vectorizer.transform(reviews_train_clean)\n",
        "X_test = wc_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75,\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "\n",
        "    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=1000)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\"\n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "\n",
        "# Accuracy for C=0.01: 0.87456\n",
        "# Accuracy for C=0.05: 0.88016\n",
        "# Accuracy for C=0.25: 0.87936\n",
        "# Accuracy for C=0.5: 0.87936\n",
        "# Accuracy for C=1: 0.87696\n",
        "\n",
        "final_wc = LogisticRegression(C=0.05, solver='lbfgs', max_iter=1000)\n",
        "final_wc.fit(X, target)\n",
        "print (\"Final Accuracy: %s\"\n",
        "       % accuracy_score(target, final_wc.predict(X_test)))\n",
        "\n",
        "# Final Accuracy: 0.88184"
      ],
      "metadata": {
        "id": "z1Pz0iBI5ZL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer.fit(reviews_train_clean)\n",
        "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
        "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "\n",
        "    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=1000)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\"\n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "\n",
        "# Accuracy for C=0.01: 0.79632\n",
        "# Accuracy for C=0.05: 0.83168\n",
        "# Accuracy for C=0.25: 0.86768\n",
        "# Accuracy for C=0.5: 0.8736\n",
        "# Accuracy for C=1: 0.88432\n",
        "\n",
        "final_tfidf = LogisticRegression(C=1, solver='lbfgs', max_iter=1000)\n",
        "final_tfidf.fit(X, target)\n",
        "print (\"Final Accuracy: %s\"\n",
        "       % accuracy_score(target, final_tfidf.predict(X_test)))\n",
        "\n",
        "# Final Accuracy: 0.882"
      ],
      "metadata": {
        "id": "svIkHEit5ZJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
        "ngram_vectorizer.fit(reviews_train_clean)\n",
        "X = ngram_vectorizer.transform(reviews_train_clean)\n",
        "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "\n",
        "    svm = LinearSVC(C=c, max_iter=1500)\n",
        "    svm.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\"\n",
        "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
        "\n",
        "# Accuracy for C=0.01: 0.89104\n",
        "# Accuracy for C=0.05: 0.88736\n",
        "# Accuracy for C=0.25: 0.8856\n",
        "# Accuracy for C=0.5: 0.88608\n",
        "# Accuracy for C=1: 0.88592\n",
        "\n",
        "final_svm_ngram = LinearSVC(C=0.01, max_iter=1500)\n",
        "final_svm_ngram.fit(X, target)\n",
        "print (\"Final Accuracy: %s\"\n",
        "       % accuracy_score(target, final_svm_ngram.predict(X_test)))\n",
        "\n",
        "# Final Accuracy: 0.8974"
      ],
      "metadata": {
        "id": "PWlS95QD5ZHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------Final Model----------------------------------------------------#\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
        "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
        "ngram_vectorizer.fit(reviews_train_clean)\n",
        "X = ngram_vectorizer.transform(reviews_train_clean)\n",
        "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
        "\n",
        "    svm = LinearSVC(C=c, max_iter=1000)\n",
        "    svm.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\"\n",
        "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
        "\n",
        "# Accuracy for C=0.001: 0.88784\n",
        "# Accuracy for C=0.005: 0.89456\n",
        "# Accuracy for C=0.01: 0.89376\n",
        "# Accuracy for C=0.05: 0.89264\n",
        "# Accuracy for C=0.1: 0.8928\n",
        "\n",
        "final = LinearSVC(C=0.01, max_iter=1000)\n",
        "final.fit(X, target)\n",
        "print (\"Final Accuracy: %s\"\n",
        "       % accuracy_score(target, final.predict(X_test)))\n",
        "\n",
        "# Final Accuracy: 0.90064\n"
      ],
      "metadata": {
        "id": "vuCNLdBf5ZGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JvAlXgB65ZCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WfIYjYDa5Y_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HAT-F1KS5Y9-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}